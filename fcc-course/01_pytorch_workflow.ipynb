{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01. PyTorch Workflow\n",
    "**Goal:** Implement an example PyTorch end-to-end workflow.\n",
    "\n",
    "Online course book: https://www.learnpytorch.io/01_pytorch_workflow/\n",
    "\n",
    "## What we're covering\n",
    "1. Data (prepare and loading)\n",
    "2. Build model\n",
    "3. Fitting the model to data (training)\n",
    "4. Making predictions and evaluating a model (inference)"
   ],
   "id": "d1029466978ad9dc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T06:24:51.903201Z",
     "start_time": "2024-07-11T06:24:47.680471Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn    # nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Data (preparing and loading)\n",
    "Data can be almost anything in Machine Learning:\n",
    "* Excel\n",
    "* Images\n",
    "* Videos\n",
    "* Audio\n",
    "* Text\n",
    "* DNA sequences and protein structures\n",
    "\n",
    "Essentially, Machine Learning consists of two parts:\n",
    "1. Create a numerical encoding of the data\n",
    "2. Build a model to learn a representation of the patterns/features\n",
    "\n",
    "To showcase this, we will go back to the basics and do some linear regression."
   ],
   "id": "19a16581414bbb5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T06:24:58.728040Z",
     "start_time": "2024-07-11T06:24:58.621536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create known parameters that we want to estimate\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)     # Generate some data and add an extra dimension\n",
    "y = weight * X + bias\n",
    "\n",
    "X.mT[:, :10], y.mT[:, :10]"
   ],
   "id": "a36e9d50c0ff50e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T06:24:59.274408Z",
     "start_time": "2024-07-11T06:24:59.251235Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape, y.shape",
   "id": "7cce2ad6e1273323",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Splitting data into training and test sets\n",
    "One of the most important points in Machine Learning.\n",
    "\n",
    "Three datasets:\n",
    "* **Training set** - used by the model to learn the underlying patterns in the data\n",
    "* **Validation set** - used to tune the hyperparameters of the model to improve *generalization*\n",
    "* **Test set** - used to evaluate model performance\n",
    "\n",
    "*Note:* The validation set can be omitted, e.g. when you only have a small dataset to start with.\n",
    "\n",
    "The model ideally never sees the data in the validation or test sets. Else the model yields inflated performance on the collected data \n",
    "sample by overfitting, which is not representative of the model's performance on unseen data.\n",
    "\n",
    "There are many possible ways to split the dataset in respect to the number of splits, cross-validation, the distribution of the data across the \n",
    "different sets, etc. "
   ],
   "id": "722c59cf6fdf3bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T06:25:25.265630Z",
     "start_time": "2024-07-11T06:25:25.253627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training/test split \n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ],
   "id": "f185c0493852278",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The above approach is bad practice since the data set is not randomly split which may introduce bias. In our case it does not matter because of the \n",
    "linear \n",
    "nature\n",
    " of  the\n",
    " problem."
   ],
   "id": "7b6c74fd952b89fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data exploration and visualization",
   "id": "84548137fb53601f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:35:09.269728Z",
     "start_time": "2024-07-11T15:35:08.974160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_predictions(\n",
    "        train_data=X_train,\n",
    "        train_labels=y_train,\n",
    "        test_data=X_test,\n",
    "        test_labels=y_test,\n",
    "        predictions=None):\n",
    "    \"\"\"Plots training data, test data, and compares predictions.\"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Test data\")\n",
    "    # Plot predictions if present\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "        \n",
    "    plt.legend(prop={\"size\": 14})\n",
    "    \n",
    "plot_predictions()"
   ],
   "id": "df6ee896fd344aa4",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Build model\n",
    "`requires_grad=True` is set by default and tells PyTorch to track the gradients for this parameter with `torch.autograd()` which is PyTorch's \n",
    "implementation for gradient computation.\n",
    "\n",
    "See: https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ],
   "id": "9777c2927eee73a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:35:10.797478Z",
     "start_time": "2024-07-11T15:35:10.769568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a linear regression model class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize model parameters\n",
    "        self.weight = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    # Define the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weight * x + self.bias"
   ],
   "id": "fa2d9bc0bee1e876",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PyTorch model building essentials\n",
    "* `torch.nn` - contains all of the building blocks for computational graphs (a neural network can be considered a computational graph)\n",
    "* `torch.nn.Parameter` - what parameters should our model try and learn, often a PyTorch layer from `torch.nn` will set these for us\n",
    "* `torch.nn.Module` - base class for all neural network building blocks. When implementing a custom neural network module, we have to implement \n",
    "the `__inti__()` and `forward()` methods. In the `__init__()` method we must call the constructor of the superclass (`nn.Module`) and define \n",
    "and initialize \n",
    "the \n",
    "parameters of the neural network module. All modules need to overwrite the `forward()` method.\n",
    "See: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "* `torch.optim` - this is where the optimizers in PyTorch live, e.g., gradient descent.\n",
    "`requires_grad=True` is set by default and tells PyTorch to track the gradients for this parameter with `torch.autograd()` which is PyTorch's \n",
    "implementation for gradient computation.\n",
    "\n",
    "PyTorch Cheat Sheet: https://pytorch.org/tutorials/beginner/ptcheat.html\n"
   ],
   "id": "4a311da08c4e4723"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Checking the contents of our model\n",
    "To check what's inside our model we can use `nn.Moduel.parameters()`."
   ],
   "id": "3515f53104413d9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:06.376155Z",
     "start_time": "2024-07-11T15:56:06.348455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a model\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check out the parameters\n",
    "list(model_0.parameters())"
   ],
   "id": "68908b0a3d21d46",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:06.533840Z",
     "start_time": "2024-07-11T15:56:06.509459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ],
   "id": "4d1d9052869773c4",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making predictions using `torch.inference_mode()`\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` given `X_test`.\n",
    "\n",
    "We pass data through the model, it's going to run it through the `forward()` method."
   ],
   "id": "d3ab1449bfbd25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:06.800377Z",
     "start_time": "2024-07-11T15:56:06.787861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred = model_0(X_test)\n",
    "    \n",
    "y_pred"
   ],
   "id": "7b69dc40716fbca1",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Running PyTorch code with `torch.inference_mode()` stops PyTorch from tracking the gradient. The `torch.inference_mode()`is new at the time of \n",
    "writing. Legacy code might use `torch.no_grad()`instead."
   ],
   "id": "c9876719c1111d5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:07.380398Z",
     "start_time": "2024-07-11T15:56:07.053462Z"
    }
   },
   "cell_type": "code",
   "source": "plot_predictions(predictions=y_pred)",
   "id": "c195bc48a9f4b96f",
   "execution_count": 92,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Because the model is initialized with random parameters, the models likely are way off from the ground truth parameters. An *ideal model* will \n",
    "exactly replicate the ground truth parameters."
   ],
   "id": "af2b6591a019bf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Train model\n",
    "During training, we update the model's parameters to better represent the data. One way to measure how poor the model's predictions is to use a \n",
    "**loss function**. The **optimizer** will take the loss of the model into account and update the model's parameters to minimize the loss function \n",
    "on the training data.\n",
    "\n",
    "**Note:** See *empirical risk minimization* (ERM) and *probably approximately correct* (PAC) learning for the theoretical foundations of why and to \n",
    "what \n",
    "extent Machine Learning works."
   ],
   "id": "b1faa4e0260d643c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:07.774563Z",
     "start_time": "2024-07-11T15:56:07.759682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pick loss function (mean absolute error, MAE)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Pick an optimizer (stochastic gradient descent, SGD)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)\n",
    "# Learning rate determines how big the scale of the parameter tweaking. This is a hyperparameter"
   ],
   "id": "d8643f3e4cc4127d",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What loss function and optimizer to pick? This depends on the problem and will become clearer with experience and reading literature.",
   "id": "8ce88dc09bc766ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building a training loop (and testing loop) in PyTorch\n",
    "Common components of a training loop:\n",
    "0. Loop through data\n",
    "1. Forwards pass \n",
    "2. Calculate the loss\n",
    "3. Reset gradients of all optimizers\n",
    "4. Backpropagation of the loss\n",
    "5. Update of the parameters"
   ],
   "id": "b6992bad851cb296"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:56:08.399516Z",
     "start_time": "2024-07-11T15:56:08.150749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 200  # Number of complete loops over data. This is a hyperparameter\n",
    "\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "# 0. Loop through data\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_0.train() # train mode tells PyTorch to track the gradients of the model parameters\n",
    "    \n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "    \n",
    "    # 2. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # 3. Reset gradients of all optimizers, by default, optimizers will accumulate the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Perform backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Testing\n",
    "    model_0.eval()  # turns off different setting not needed for evaluation (e.g., drop out layers, batch norm layers,...)\n",
    "    with torch.inference_mode():    # turns off gradient tracking\n",
    "        # 1. Forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "        \n",
    "        # 2. Calculate test loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(f\"Training loss: {loss} | Test loss: {test_loss}\")\n",
    "        print(f\"{model_0.state_dict()}\\n\")"
   ],
   "id": "2c7db4a21309495e",
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred_new = model_0(X_test)\n",
    "    plot_predictions(predictions=y_pred_new)"
   ],
   "id": "a2f22f5411c8fdf8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the loss values\n",
    "plt.plot(epoch_count, torch.tensor(loss_values).numpy(), label=\"Training loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ],
   "id": "f134ad0f7fba68af",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Saving a model in PyTorch\n",
    "\n",
    "There are three main methods for saving and loading models in PyTorch:\n",
    "1. `torch.save()` - allows you to save a PyTorch object in Python's pickle format\n",
    "2. `torch.load()` - allows you to load a saved PyTorch object\n",
    "3. `torch.nn.Modules.load_state_dict()` - allows to load a model's saved state dictionary\n",
    "\n",
    "Reference: https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ],
   "id": "27a8e9aaacd4ed9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:27:09.616545Z",
     "start_time": "2024-07-11T16:27:09.605249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving our PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create model dictionary\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving the model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ],
   "id": "fe880e704cc25b6c",
   "execution_count": 100,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:28:11.267002Z",
     "start_time": "2024-07-11T16:28:11.260003Z"
    }
   },
   "cell_type": "code",
   "source": "# !ls -l models",
   "id": "dbdcc5515aab35c4",
   "execution_count": 102,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading a PyTorch model\n",
    "Since we saved our model's `state_dict()` rather than the entire model, we'll create a new instance of our model class and load the saved \n",
    "`state_dict()` into it."
   ],
   "id": "81bd9d924b5bad9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:36:38.669248Z",
     "start_time": "2024-07-11T16:36:38.647645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To load the saved stated_dict we first have to instantiate a new object of our model class\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the saved state_dict of model_0 (this will update the new instance with provided parameters)\n",
    "loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ],
   "id": "3a64dc507622a1dd",
   "execution_count": 107,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:36:40.161117Z",
     "start_time": "2024-07-11T16:36:40.138299Z"
    }
   },
   "cell_type": "code",
   "source": "loaded_model_0.state_dict(), model_0.state_dict()",
   "id": "ec050cbedffc4615",
   "execution_count": 108,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:40:14.717951Z",
     "start_time": "2024-07-11T16:40:14.698738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make some predictions with the loaded model\n",
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_pred = loaded_model_0(X_test)\n",
    "    original_model_pred = model_0(X_test)\n",
    "loaded_model_pred.mT, original_model_pred.mT, (loaded_model_pred == original_model_pred).mT"
   ],
   "id": "9607377318bed918",
   "execution_count": 111,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Putting it all together",
   "id": "955377a68fe89ee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:44:34.630697Z",
     "start_time": "2024-07-11T16:44:34.604330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "c5fe76c71ed577cb",
   "execution_count": 113,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.1 Data\n",
    "We will use the same dummy-dataset as before."
   ],
   "id": "95b0877fa9fa70f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 Build a linear PyTorch model",
   "id": "6678d4a2c578c473"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:53:13.300533Z",
     "start_time": "2024-07-11T16:53:13.217308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # This time us a linear layer (fully connected layer) instead of instantiating the parameters manually\n",
    "        self.linear = nn.Linear(in_features=1, out_features=1, bias=True)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelV2()\n",
    "\n",
    "model_1, model_1.state_dict()"
   ],
   "id": "86753e034060c58f",
   "execution_count": 114,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:54:41.624099Z",
     "start_time": "2024-07-11T16:54:41.612018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the model current device\n",
    "next(model_1.parameters()).device"
   ],
   "id": "79fd075b7fe2036d",
   "execution_count": 115,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:55:16.294879Z",
     "start_time": "2024-07-11T16:55:16.285359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the model to use the target device\n",
    "model_1.to(device)\n",
    "next(model_1.parameters()).device"
   ],
   "id": "3e7c5647a7f54a21",
   "execution_count": 117,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3 Training\n",
    "For training we need:\n",
    "1. A loss function\n",
    "2. An optimizer\n",
    "3. A training loop"
   ],
   "id": "dc27cbcf8b178d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:57:29.896847Z",
     "start_time": "2024-07-11T16:57:29.878971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reuse loss function from previous example\n",
    "optimizer_1 = torch.optim.SGD(params=model_1.parameters(), lr=0.01)"
   ],
   "id": "c6bc3146b5520747",
   "execution_count": 118,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:05:23.293667Z",
     "start_time": "2024-07-11T17:05:23.108204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Put data on the target device\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "epoch_count_1 = []\n",
    "loss_values_1 = []\n",
    "test_loss_values_1 = []\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "    y_pred_1 = model_1(X_train)\n",
    "    loss_1 = loss_fn(y_pred_1, y_train)\n",
    "    optimizer_1.zero_grad()\n",
    "    loss_1.backward()\n",
    "    optimizer_1.step()\n",
    "    \n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred_1 = model_1(X_test)\n",
    "        test_loss_1 = loss_fn(test_pred_1, y_test)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count_1.append(epoch)\n",
    "        loss_values_1.append(loss_1)\n",
    "        test_loss_values_1.append(test_loss_1)\n",
    "        \n",
    "        print(f\"\"\"\n",
    "            Epoch: {epoch} | Training loss: {loss_1} | Test loss: {test_loss_1}\n",
    "            {model_1.state_dict()}\n",
    "        \"\"\")"
   ],
   "id": "f567b4cbbbfeb8be",
   "execution_count": 119,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.4 Evaluate predictions",
   "id": "a3d9f9398bd11e42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:09:17.650251Z",
     "start_time": "2024-07-11T17:09:17.264989Z"
    }
   },
   "cell_type": "code",
   "source": "plot_predictions(predictions=test_pred_1.cpu())",
   "id": "f4aa8e74d8495834",
   "execution_count": 121,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:13:46.935421Z",
     "start_time": "2024-07-11T17:13:46.785920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot learning curves\n",
    "plt.plot(epoch_count_1, torch.tensor(loss_values_1).numpy(), label=\"Training data\")\n",
    "plt.plot(epoch_count_1, test_loss_values_1, label=\"Test data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a9b5cdf139d2a5c",
   "execution_count": 122,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.5 Save and load model",
   "id": "8b74db9647478e72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:18:52.727693Z",
     "start_time": "2024-07-11T17:18:52.701414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "MODEL_NAME_1 = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH_1 = MODEL_PATH / MODEL_NAME_1\n",
    "\n",
    "torch.save(model_1.state_dict(), MODEL_SAVE_PATH_1)\n",
    "\n",
    "# Load model\n",
    "loaded_model_1 = LinearRegressionModelV2()\n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH_1))"
   ],
   "id": "db5d449b23bae12",
   "execution_count": 123,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:21:15.205494Z",
     "start_time": "2024-07-11T17:21:15.174130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_pred_1 = loaded_model_1(X_test)\n",
    "    original_model_pred_1 = model_1(X_test)\n",
    "\n",
    "loaded_model_pred_1.mT, original_model_pred_1.mT, (loaded_model_pred_1 == original_model_pred_1).mT"
   ],
   "id": "bd712d567176f83a",
   "execution_count": 124,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
