{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNVT0p6cmTbn0R4LFJNl5DA",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3416486b0c2047de8007debf68c77cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e0f3a0027884ed3ae0c42738000ef31",
       "IPY_MODEL_b4620aa1740c42088bb127f6b3343ca4",
       "IPY_MODEL_836ec6eee6684aec8244b81c8103978e"
      ],
      "layout": "IPY_MODEL_d917e70a647f4877ad84e477e2be83b9"
     }
    },
    "6e0f3a0027884ed3ae0c42738000ef31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0430cb2170904ec8822336ed3c98bbae",
      "placeholder": "​",
      "style": "IPY_MODEL_17ca7ef4a8564031ba6c80a44cf1368b",
      "value": "100%"
     }
    },
    "b4620aa1740c42088bb127f6b3343ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4652686c952349c2b632137732f44b78",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db33ab07b21247878b2b0da10b4c1c20",
      "value": 3
     }
    },
    "836ec6eee6684aec8244b81c8103978e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bbc3633181b4b89b4c28da525873739",
      "placeholder": "​",
      "style": "IPY_MODEL_467f773fbd8d45558587a1e1d2d86713",
      "value": " 3/3 [00:37&lt;00:00, 12.46s/it]"
     }
    },
    "d917e70a647f4877ad84e477e2be83b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0430cb2170904ec8822336ed3c98bbae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17ca7ef4a8564031ba6c80a44cf1368b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4652686c952349c2b632137732f44b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db33ab07b21247878b2b0da10b4c1c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0bbc3633181b4b89b4c28da525873739": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "467f773fbd8d45558587a1e1d2d86713": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tonyzamyatin/learning-pytorch/blob/master/03_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 03. PyTorch Computer Vision\n",
    "\n",
    "Online Course Book: https://www.learnpytorch.io/03_pytorch_computer_vision/"
   ],
   "metadata": {
    "id": "8Wt61ch5v1j6"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-z-QqtbmEzM",
    "outputId": "8eb355a7-a8c4-4b12-88a1-b4db569665b7",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:09.382380Z",
     "start_time": "2024-07-30T06:55:09.364052Z"
    }
   },
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:12.719720Z",
     "start_time": "2024-07-30T06:55:09.569447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    # Note: you need the \"raw\" GitHub URL for this to work\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/tonyzamyatin/learning-pytorch/master/fcc-course/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Getting a dataset\n",
    "For our first computer vision task we will go with the glorious FashionMNIST dataset, made by Zalando research. It contains low resolution grey scale images of 10 different kinds of clothing."
   ],
   "metadata": {
    "id": "8XcMWy1vwFkJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",  # where to download data\n",
    "    train=True,  # get training data\n",
    "    download=True,  # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(),  # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None  # don't transform the labels though\n",
    ")\n",
    "\n",
    "# Setup test data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "id": "-qFOHhevwEX9",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:12.892503Z",
     "start_time": "2024-07-30T06:55:12.725721Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's inspect the first sample of the training data."
   ],
   "metadata": {
    "id": "6UgxlfjHxajX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRZmYJnkxVdD",
    "outputId": "787b176d-8320-48db-a87b-e929365367c3",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:12.923254Z",
     "start_time": "2024-07-30T06:55:12.895503Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Input and output shapes of a computer vision model"
   ],
   "metadata": {
    "id": "8r3AXgUIxmLm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk36Yty2xjV7",
    "outputId": "bdd278a2-49d9-447d-c161-dba3af456b3d",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:49.185420Z",
     "start_time": "2024-07-30T06:55:49.173818Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have one color channel and a width and height of 28 pixels.\n",
    "\n",
    "There is debate whether CHW or HWC is the better way to represent an image. Anyway, PyTorch accepts NCHW as default, but at the same time explains that NHWC performs better and is considered best practice."
   ],
   "metadata": {
    "id": "73M0d2pLxy6x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of samples\n",
    "len(train_data), len(test_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kiix4DlfxymV",
    "outputId": "94ef3d31-e062-4303-f62d-8aba83b669e7",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:51.076082Z",
     "start_time": "2024-07-30T06:55:51.045412Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 60k training images and 10k test images."
   ],
   "metadata": {
    "id": "1yAkqpllyjt4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspect available classes\n",
    "class_names = train_data.classes\n",
    "class_names"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ot9jXTayjc1",
    "outputId": "ba48db06-037a-46f1-cc8f-3c390656c0c5",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:51.920947Z",
     "start_time": "2024-07-30T06:55:51.909760Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we have 10 different classes. we're dealing with a multi-classification problem yet again."
   ],
   "metadata": {
    "id": "R56U3MaizKqm"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### 1.2 Visualize and explore our data",
   "metadata": {
    "id": "9DLS4k-OzRks"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape:\", image.shape)\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "VdhpqglozRWz",
    "outputId": "efd830db-e954-47bf-d753-6b9c08348614",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:54.185536Z",
     "start_time": "2024-07-30T06:55:53.568173Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To turn images into greyscale we use the ˋcmapˋ parameter of ˋplt.imshow()ˋ."
   ],
   "metadata": {
    "id": "qmrC24Tgzl5P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "kcuxImB8zlqg",
    "outputId": "17c8d338-71cc-4ce8-862d-b782dfcb3ecf",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:54.872960Z",
     "start_time": "2024-07-30T06:55:54.738436Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot some more images."
   ],
   "metadata": {
    "id": "6izyQKZDz37Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "sB59WBf0xuYU",
    "outputId": "f377e4b0-f6b0-43d2-bc48-423c208d03bf",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:58.084698Z",
     "start_time": "2024-07-30T06:55:55.482890Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's have a look at the class distribution of our datasets."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T06:55:59.444091Z",
     "start_time": "2024-07-30T06:55:59.432914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mnist_class_count(dataset: torchvision.datasets.MNIST):\n",
    "    \"\"\"\n",
    "    Count the classes of an MNIST dataset.\n",
    "    :param dataset: A dataset subclassing `torchvision.datasets.mnist.MNIST`\n",
    "    :return: a dictionary of the class names and their frequency in the dataset\n",
    "    \"\"\"\n",
    "    class_count = {name: 0 for name in dataset.classes}\n",
    "    for img, label in dataset:\n",
    "        class_count[dataset.classes[label]] += 1\n",
    "    \n",
    "    return class_count"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T11:28:24.843156Z",
     "start_time": "2024-07-29T11:28:18.840021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_class_count = get_mnist_class_count(train_data)\n",
    "print(f\"Train data class count:\\n{train_class_count}\")\n",
    "test_class_count = get_mnist_class_count(test_data)\n",
    "print(f\"Test data class count:\\n{test_class_count}\")"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The classes of our datasets are nicely evenly distributed.\n",
    "\n",
    "**Note**: This is a toy dataset and in real world scenarios we will likely have to deal with skewed data distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Prepare DataLoader",
   "metadata": {
    "id": "9HYbClW40dDv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(f\"Data loaders: {train_dl, test_dl}\")\n",
    "print(f\"Length of train data loader: {len(train_dl)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test data loader: {len(test_dl)} batches of {BATCH_SIZE}...\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7k7YU3Bc0czz",
    "outputId": "00bb1c72-313a-4e1f-e655-7e4bfa73bced",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:56:03.038213Z",
     "start_time": "2024-07-30T06:56:03.026690Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Build a baseline model\n"
   ],
   "metadata": {
    "id": "obHKelyN1q1G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ],
   "metadata": {
    "id": "jdpmD75h1qlm",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:56:04.240504Z",
     "start_time": "2024-07-30T06:56:04.227980Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names)).to(\"cpu\")"
   ],
   "metadata": {
    "id": "hd2nR74x0J7D",
    "ExecuteTime": {
     "end_time": "2024-07-30T06:56:05.601686Z",
     "start_time": "2024-07-30T06:56:05.581685Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.1 Setup loss, optimizer and evaluation metrics",
   "metadata": {
    "id": "vu8q2RT23Tl7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.01)"
   ],
   "metadata": {
    "id": "ouCGgzuq3pmx",
    "jupyter": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Creating a function to time our experiments\n",
    "Let's do a small experiment and compare the time it takes to run the model on a GPU versus on a CPU.\n",
    "\n",
    "Our timing function will use ˋtimeit.default_timer()ˋ from the ˋtimeitˋ module."
   ],
   "metadata": {
    "id": "izCUkhe04mKs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ],
   "metadata": {
    "id": "-Nr-axKI4BxK",
    "ExecuteTime": {
     "end_time": "2024-07-29T12:07:25.586083Z",
     "start_time": "2024-07-29T12:07:25.581121Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Training loop on batches of data"
   ],
   "metadata": {
    "id": "Ps4Ctyy35hb9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch + 1}\\n---------\")\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dl):\n",
    "        model_0.train()\n",
    "        y_pred = model_0(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dl.dataset)} samples\")\n",
    "\n",
    "    # Average loss per batch per epoch\n",
    "    train_loss /= len(train_dl)\n",
    "\n",
    "    # Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dl:\n",
    "            test_pred = model_0(X_test)\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(test_dl)\n",
    "        test_acc /= len(test_dl)\n",
    "\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(\n",
    "    start=train_time_start_on_cpu,\n",
    "    end=train_time_end_on_cpu,\n",
    "    device=\"cpu\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587,
     "referenced_widgets": [
      "3416486b0c2047de8007debf68c77cb3",
      "6e0f3a0027884ed3ae0c42738000ef31",
      "b4620aa1740c42088bb127f6b3343ca4",
      "836ec6eee6684aec8244b81c8103978e",
      "d917e70a647f4877ad84e477e2be83b9",
      "0430cb2170904ec8822336ed3c98bbae",
      "17ca7ef4a8564031ba6c80a44cf1368b",
      "4652686c952349c2b632137732f44b78",
      "db33ab07b21247878b2b0da10b4c1c20",
      "0bbc3633181b4b89b4c28da525873739",
      "467f773fbd8d45558587a1e1d2d86713"
     ]
    },
    "id": "SQOSEIlN5hKg",
    "outputId": "8426a321-72e4-4dc6-ba1b-fcb53631b8c6",
    "ExecuteTime": {
     "end_time": "2024-07-29T12:07:52.052585Z",
     "start_time": "2024-07-29T12:07:27.726642Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The baseline model did already do quite well. Let's evaluate the model.",
   "metadata": {
    "id": "k7wIrvwIkqz0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluate Model 0"
   ],
   "metadata": {
    "id": "JKYLHGMmkxHQ"
   }
  },
  {
   "cell_type": "code",
   "source": "!pip install torchmetrics",
   "metadata": {
    "id": "tQkgZEmFkqjF",
    "outputId": "60952ee3-f6c4-41e4-d20d-3265f6449ab9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:07:53.490500Z",
     "start_time": "2024-07-29T12:07:52.066125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper_functions import print_eval_metrics, eval_model\n",
    "from torchmetrics import MetricCollection, Accuracy, Recall, Precision, F1Score, AUROC, ConfusionMatrix\n",
    "\n",
    "metrics = MetricCollection({\n",
    "        \"accuracy\": Accuracy(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "        \"recall\": Recall(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "        \"precision\": Precision(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "        \"f1-score\": F1Score(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "        \"auroc\": AUROC(task=\"multiclass\", num_classes=10),\n",
    "        \"confmat\": ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "})\n",
    "\n",
    "loss, updated_metrics = eval_model(model_0, test_dl, loss_fn, metrics)\n",
    "computed_metrics = {name: metric.compute() for name, metric in updated_metrics.items() if name != \"confmat\"}\n",
    "\n",
    "print(f\"EVALUATION of {model_0.__class__.__name__}\")\n",
    "print_eval_metrics(loss, computed_metrics)\n",
    "\n",
    "metrics['confmat'].plot()"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:02.891473Z",
     "start_time": "2024-07-29T12:08:02.880604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "from pathlib import Path\n",
    "MODELS_DIR_PATH = Path(\"models\")\n",
    "MODEL_NAME_0 = \"03_pytorch_cv_model_0.pth\"\n",
    "MODELS_DIR_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_SAVE_PATH_0 = MODELS_DIR_PATH / MODEL_NAME_0\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH_0)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Setup device agnostic-code"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:03.743700Z",
     "start_time": "2024-07-29T12:08:03.736994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Model 1: Building a better model with non-linearity"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:04.684628Z",
     "start_time": "2024-07-29T12:08:04.679856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_units: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:05.800992Z",
     "start_time": "2024-07-29T12:08:05.443762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = FashionMNISTModelV1(28**2, 10, len(class_names)).to(device)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 Setup loss, optimizer and metrics"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:06.996683Z",
     "start_time": "2024-07-29T12:08:06.983229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics.wrappers import MetricTracker\n",
    "from torchmetrics import MetricCollection, ConfusionMatrix, AUROC, F1Score, Precision, Recall, Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.01)\n",
    "\n",
    "train_metrics = MetricCollection({\n",
    "    'accuracy': Accuracy(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'f1_score': F1Score(task=\"multiclass\", num_classes=10, average='macro')\n",
    "})\n",
    "\n",
    "test_metrics = MetricCollection({\n",
    "    'accuracy': Accuracy(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'recall': Recall(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'precision': Precision(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'f1_score': F1Score(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'auroc': AUROC(task=\"multiclass\", num_classes=10, average='macro'),\n",
    "    'confmat': ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "})\n",
    "\n",
    "train_metric_tracker = MetricTracker(train_metrics)\n",
    "test_metric_tracker = MetricTracker(test_metrics)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.2 Create training and testing loop\n",
    "I defined to functions `run_epoch()` and `plot_confusion_matrix()` in `helper_functions.py` to simplify the training-testing loop."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:38.560274Z",
     "start_time": "2024-07-29T12:08:08.278722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from helper_functions import plot_confusion_matrix, run_epoch\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"\\nEPOCH {epoch+1}\\n---------\")\n",
    "    train_loss, train_metric_tracker = run_epoch(\n",
    "        model=model_1,\n",
    "        data_loader=train_dl,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        metric_tracker=train_metric_tracker,\n",
    "        device=device\n",
    "    )\n",
    "    computed_train_metrics = train_metric_tracker.compute()\n",
    "    print(\"Training metrics:\")\n",
    "    print_eval_metrics(train_loss, computed_train_metrics)\n",
    "    \n",
    "    test_loss, test_metric_tracker = run_epoch(\n",
    "        model=model_1,\n",
    "        data_loader=test_dl,\n",
    "        loss_fn=loss_fn,\n",
    "        metric_tracker=test_metric_tracker,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    computed_test_metrics = test_metric_tracker.compute()\n",
    "    print(\"\\nTest metrics:\")\n",
    "    print_eval_metrics(test_loss, {k: v for k, v in computed_test_metrics.items() if k != 'confmat'})\n",
    "    \n",
    "    if epoch == epochs - 1:\n",
    "        confusion_matrix = computed_test_metrics['confmat']\n",
    "        plot_confusion_matrix(confusion_matrix, class_names)\n",
    "        \n",
    "train_time_end_on_gpu = timer()\n",
    "print()\n",
    "total_train_time_model_1 = print_train_time(train_time_start_on_gpu, train_time_end_on_gpu, device)\n"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Awesome! But it looks like it longer to train the model on the GPU than on the CPU. How can that be?\n",
    "> Well, one reason could be because your dataset and model are both so small (like the dataset and model we're working with) the benefits of using a\n",
    " GPU are outweighed by the time it actually takes to transfer the data there. There's a small bottleneck between copying data from the CPU memory (default) to the GPU memory. So for smaller models and datasets, the CPU might\n",
    "  actually be the optimal place to compute on.\n",
    "But for larger datasets and models, the speed of computing the GPU can offer usually far outweighs the cost of getting the data there.\n",
    "However, this is largely dependant on the hardware you're using. With practice, you will get used to where the best place to train your models is."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:08:40.039715Z",
     "start_time": "2024-07-29T12:08:40.032661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "MODEL_NAME_1 = \"03_pytorch_cv_model_1.pth\"\n",
    "MODEL_SAVE_PATH_1 = MODELS_DIR_PATH / MODEL_NAME_1\n",
    "\n",
    "torch.save(obj=model_1, f=MODEL_SAVE_PATH_1)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's compare the two models!"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T12:10:49.882615Z",
     "start_time": "2024-07-29T12:10:47.807254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_metrics.reset()\n",
    "loss_0, test_metrics_0 = eval_model(model_0, test_dl, loss_fn, test_metrics)\n",
    "eval_0 = {name: metric.compute() for name, metric in test_metrics_0.items() if name != \"confmat\"}\n",
    "\n",
    "test_metrics.reset()\n",
    "loss_1, test_metrics_1 = eval_model(model_1, test_dl, loss_fn, test_metrics)\n",
    "eval_1 = {name: metric.compute() for name, metric in test_metrics_1.items() if name != \"confmat\"}\n",
    "\n",
    "print(f\"EVALUATION of {model_0.__class__.__name__}\")\n",
    "print_eval_metrics(loss_0, eval_0)\n",
    "print(f\"\\nEVALUTATION of {model_1.__class__.__name__}\")\n",
    "print_eval_metrics(loss_1, eval_1)"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Interesting. In this case, it looks like adding non-linearity to our model made it perform worse than the baseline.\n",
    "\n",
    "> That's a thing to note in machine learning, sometimes the thing you thought should work doesn't. And then the thing you thought might not work does.\n",
    "\n",
    "Most likely, the model is overfitting to the training data.\n",
    "\n",
    "Two main (simplest) ways to fix overfitting include:\n",
    "1. Use a smaller or different model (some models fir certain kinds of data better than others)\n",
    "2. Use a larger dataset (the more data, the more chance the model has to learn generalizable patterns)\n",
    "\n",
    "There are also more ways to prevent overfitting in machine learning (e.g. regularization). Researching this is part of the extracurricular.\n",
    "\n",
    "In the meantime, we will try method 1 - using a different model architecture."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Model 2: Build a Convolutional Neural Network (CNN)\n",
    "CNNs are known for their capacity to find patterns in visual data (although their application extends way beyond just images).\n",
    "\n",
    "Let's see if a CNN model can improve upon our baseline. The CNN model we're going to be using it known as TinyVGG from https://poloclub.github.io/cnn-explainer.\n",
    "\n",
    "It follows the typical structure of a CNN:\n",
    "\n",
    "`Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer`\n",
    "\n",
    "The convolutional blocks can be upscaled and repeated multiple times, depending on requirements."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What model to use?\n",
    "\n",
    "| Problem type                          | Model to use (generally)                          | Code example                           |\n",
    "|---------------------------------------|---------------------------------------------------|----------------------------------------|\n",
    "| Structured data (Excel spreadsheets, row and column data) | Gradient boosted models, Random Forests, XGBoost | sklearn.ensemble, XGBoost library      |\n",
    "| Unstructured data (images, audio, language) | Convolutional Neural Networks, Transformers       | torchvision.models, HuggingFace Transformers |\n",
    "\n",
    "This is only a tiny, arbitrarily picked set of models. In reality, there are many more and the one to use depends on the problem at hand and the \n",
    "specific project requirements."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:16:31.070157Z",
     "start_time": "2024-07-29T13:16:31.056633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_units: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_size,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                           stride=2)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                      out_features=output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(1, 10, len(class_names)).to(device)\n",
    "\n",
    "model_2"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nice! This is the biggest model of the course yet.\n",
    "\n",
    "What we have done is common practice in machine learning:\n",
    "\n",
    "\"Find a model architecture somewhere and replicate it with code.\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### CNN architecture\n",
    "\n",
    "The two new layers we use in a CNN are the convolutional layer and the max-pooling layer:\n",
    "- `nn.Conv2d`: the convolutional layer performs a two-dimensional convolution on the input tensor. There are also 1D and 3D convolutions \n",
    "implemented in PyTorch. To understand what a convolution is, how it works inside CNNs and what the hyperparameters mean, see:[CNN Explainer \n",
    "website](https://poloclub.github.io/cnn-explainer/), [CNNs Explained](https://youtu.be/pj9-rr1wDhM?si=U9EoZQDSyJIWVQlD), and [But what is a \n",
    "convolution?](https://youtu.be/KuXjwB4LzSA?si=kSr1_3yI-VOnuR3r).\n",
    "- `nn.MaxPool2d`: the max-pooling layer performs further compression of the convolutional layer output by moving another kernel over the input \n",
    "and only selecting (pooling) the maximum value inside the kernel into the output tensor. For a visual explainer see [CNNs Explained](https://youtu\n",
    ".be/pj9-rr1wDhM?si=U9EoZQDSyJIWVQlD)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.3 Setup a loss function, optimizer and metrics for Model 2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:16:33.244148Z",
     "start_time": "2024-07-29T13:16:33.235100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), lr=0.01)\n",
    "\n",
    "train_metric_tracker.reset_all()\n",
    "test_metric_tracker.reset()"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.4 Train and test Model 2\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:17:08.895638Z",
     "start_time": "2024-07-29T13:16:34.740965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from helper_functions import run_epoch, plot_confusion_matrix\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"\\nEPOCH {epoch+1}\\n---------\")\n",
    "    train_loss, train_metric_tracker = run_epoch(model_2, train_dl, loss_fn, optimizer, train_metric_tracker, device)\n",
    "    computed_train_metrics = train_metric_tracker.compute()\n",
    "    print(\"TRAINING:\")\n",
    "    print_eval_metrics(train_loss, computed_train_metrics)\n",
    "    \n",
    "    test_loss, test_metric_tracker = run_epoch(model_2, test_dl, loss_fn, optimizer=None, metric_tracker=test_metric_tracker, device=device)\n",
    "    computed_test_metrics = test_metric_tracker.compute()\n",
    "    print(\"TESTING:\")\n",
    "    print_eval_metrics(test_loss, {k: v for k, v in computed_test_metrics.items() if k != 'confmat'})\n",
    "    \n",
    "    if epoch == epochs - 1:\n",
    "        confusion_matrix = computed_test_metrics['confmat']\n",
    "        plot_confusion_matrix(confusion_matrix, class_names)\n",
    "   \n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(train_time_start_model_2, train_time_end_model_2, device)"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:24:12.254747Z",
     "start_time": "2024-07-29T13:24:10.175164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_metrics.reset()\n",
    "loss_2, test_metrics_2 = eval_model(model_2, test_dl, loss_fn, test_metrics)\n",
    "eval_2 = {name: metric.compute() for name, metric in test_metrics_2.items() if name != \"confmat\"}"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Compare model results and training time\n",
    "We've trained three different models:\n",
    "1. `model_0` - our baseline model with two `nn.Linear()` layers.\n",
    "2. `model_1` - the same setup as the baseline model except that it uses `nn.ReLU()` as activation function\n",
    "3. `model_2` - our CNN that mimics TinyVGG architecture on the CNN Explainer website\n",
    "\n",
    "This is a regular practice in ML: Build multiple models and perform multiple training experiments to see which performs best.\n",
    "\n",
    "Let's combine the model results into a data frame and find out."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:35:19.986102Z",
     "start_time": "2024-07-29T13:35:19.973755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def format_eval(eval: Dict[str, torch.Tensor]):\n",
    "    return {k.capitalize(): f\"{100 * v.item():.2f}%\" for k, v in eval.items()}\n",
    "\n",
    "\n",
    "model_benchmark = pd.DataFrame([\n",
    "    format_eval(eval_0), \n",
    "    format_eval(eval_1), \n",
    "    format_eval(eval_2)\n",
    "])\n",
    "model_benchmark['Training time'] = [\n",
    "    f\"{total_train_time_model_0:.1f} s\",\n",
    "    f\"{total_train_time_model_1:.1f} s\",\n",
    "    f\"{total_train_time_model_2:.1f} s\"\n",
    "]\n",
    "model_benchmark"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It looks like our CNN model performed the best but also was the slowest during training. And our baseline model performed better then `model_1`."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Performance-speed tradeoff\n",
    "Something to be aware of in machine learning is the **performance-speed** tradeoff.\n",
    "\n",
    "Generally, you get better performance out of a larger, more complex model (like our CNN). However, this kind of performance increase often comes at\n",
    " a sacrifice of training and inference speed, and at the risk of overfitting to the dataset used to train and evaluate the model."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Plot a confusion matrix"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# First make some predictions\n",
    "y_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dl, desc=\"Making predictions\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_logit = model_2(X)\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        y_preds.append(y_pred.cpu())\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T13:44:02.153949Z",
     "start_time": "2024-07-29T13:43:59.842575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See if mlxtend exists, if not, install it\n",
    "try:\n",
    "    import mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
    "except:\n",
    "    !pip install mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
    "    import mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "confmat = ConfusionMatrix(task='multiclass', num_classes=len(class_names))\n",
    "confmat_tensor = confmat(y_pred_tensor, test_data.targets)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Save and load best performing model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODELS_DIR_PATH = Path('models')\n",
    "MODELS_DIR_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME_2 = \"03_pytorch_cv_model_2.pth\"\n",
    "MODEL_SAVE_PATH_2 = MODELS_DIR_PATH / MODEL_NAME_2\n",
    "\n",
    "torch.save(obj=model_2.state_dict(), f=MODEL_SAVE_PATH_2)"
   ],
   "outputs": []
  }
 ]
}
